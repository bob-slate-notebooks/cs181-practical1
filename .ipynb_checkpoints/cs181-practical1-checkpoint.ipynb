{
 "metadata": {
  "name": "",
  "signature": "sha256:7f2c51a0dd50d8814d984575b0c5aaf65dd91c48cfb81746c6f6114a164c2f2c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import gzip\n",
      "import numpy as np\n",
      "from sklearn import linear_model \n",
      "from sklearn.metrics import mean_squared_error\n",
      "from math import sqrt\n",
      "from rdkit.Chem import AllChem\n",
      "\n",
      "train_filename = 'train.csv.gz'\n",
      "test_filename = 'train.csv.gz'\n",
      "#test_filename  = 'test.csv.gz'\n",
      "pred_filename  = 'lasso_prediction.csv'\n",
      "\n",
      "# Load the training file.\n",
      "train_data = []\n",
      "with gzip.open(train_filename, 'r') as train_fh:\n",
      "\n",
      "    # Parse it as a CSV file.\n",
      "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
      "    \n",
      "    # Skip the header row.\n",
      "    next(train_csv, None)\n",
      "\n",
      "    # Load the data. \n",
      "    counter = 0\n",
      "\n",
      "    for row in train_csv: \n",
      "        smiles   = row[0]\n",
      "        if counter >= 30000:\n",
      "            break\n",
      "        #features = np.array([float(x) for x in row[1:257]])\n",
      "        gap      = float(row[257])\n",
      "        mol = AllChem.MolFromSmiles(smiles)\n",
      "        features = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048, useFeatures=True)\n",
      "        counter+=1\n",
      "        train_data.append({ 'smiles':   smiles,\n",
      "                            'features': features,\n",
      "                            'gap':      gap })"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute the mean of the gaps in the training data.\n",
      "gaps_train = np.array([datum['gap'] for datum in train_data])\n",
      "features_train = np.array([datum['features'] for datum in train_data])\n",
      "\n",
      "'''cutoff = 40000\n",
      "gaps_train = np.hsplit(gaps, [cutoff])[0]\n",
      "features_train = np.vsplit(features, [cutoff])[0]\n",
      "gaps_test = np.hsplit(gaps, [cutoff])[1]\n",
      "features_test = np.vsplit(features, [cutoff])[1]'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'cutoff = 40000\\ngaps_train = np.hsplit(gaps, [cutoff])[0]\\nfeatures_train = np.vsplit(features, [cutoff])[0]\\ngaps_test = np.hsplit(gaps, [cutoff])[1]\\nfeatures_test = np.vsplit(features, [cutoff])[1]'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run this cell when uploading to Kaggle\n",
      "pred_filename  = 'rdk_ridge_prediction2.csv'\n",
      "test_filename = 'test.csv.gz'\n",
      "\n",
      "# Load the test file.\n",
      "test_data = []\n",
      "with gzip.open(test_filename, 'r') as test_fh:\n",
      "\n",
      "    # Parse it as a CSV file.\n",
      "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
      "    \n",
      "    # Skip the header row.\n",
      "    next(test_csv, None)\n",
      "\n",
      "    # Load the data.\n",
      "    for row in test_csv:\n",
      "        id       = row[0]\n",
      "        smiles   = row[1]\n",
      "        #features = np.array([float(x) for x in row[2:258]])\n",
      "        features = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048, useFeatures=True)\n",
      "\n",
      "        test_data.append({ 'id':       id,\n",
      "                           'smiles':   smiles,\n",
      "                           'features': features })\n",
      "        \n",
      "# Get features of the test data\n",
      "features_test = np.array([datum['features'] for datum in test_data])\n",
      "# Get ids of the test data\n",
      "ids_test = np.array([datum['id'] for datum in test_data])\n",
      "\n",
      "alpha = 0.9\n",
      "clf = linear_model.Ridge(alpha, max_iter=100000000)\n",
      "clf = clf.fit(features_train, gaps_train) # feature vectors (row is ohhhone data point), label/gap/thing\n",
      "result_gaps = clf.predict(features_test) # call on feature vectors # parameter is second half of the data\n",
      "\n",
      "# Write a prediction file.\n",
      "with open(pred_filename, 'w') as pred_fh:\n",
      "\n",
      "    # Produce a CSV file.\n",
      "    pred_csv = csv.writer(pred_fh, delimiter=',', quotechar='\"')\n",
      "\n",
      "    # Write the header row.\n",
      "    pred_csv.writerow(['Id', 'Prediction'])\n",
      "\n",
      "    for i in xrange(0, len(ids_test)):\n",
      "        pred_csv.writerow([ids_test[i], result_gaps[i]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print gaps_train.shape\n",
      "print features_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50001,)\n",
        "(50001, 2048)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cut it off early to do the features \n",
      "for i in range(-3, 12):\n",
      "    alpha = 10 ** (-i)\n",
      "    clf = linear_model.Ridge(alpha, max_iter=1000000000)\n",
      "    # clf = linear_model.ElasticNet(alpha, 0.3, max_iter = 100000000)\n",
      "    clf = clf.fit(features_train, gaps_train) # feature vectors (row is one data point), label/gap/thing\n",
      "    result_gaps = clf.predict(features_test) # call on feature vectors # parameter is second half of the data\n",
      "    \n",
      "    #print result_gaps\n",
      "    # Write a prediction file.\n",
      "    # with open(pred_filename, 'w') as pred_fh:\n",
      "\n",
      "    #     # Produce a CSV file.\n",
      "    #     pred_csv = csv.writer(pred_fh, delimiter=',', quotechar='\"')\n",
      "\n",
      "    #     # Write the header row.\n",
      "    #     pred_csv.writerow(['Id', 'Prediction'])\n",
      "\n",
      "    #     for datum in features_test:\n",
      "    #         pred_csv.writerow([1, result_gaps])\n",
      "\n",
      "    rms = sqrt(mean_squared_error(gaps_test, result_gaps))\n",
      "    print str(alpha) +  \",\" + str(rms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000,0.194217575474\n",
        "100,0.177677504476"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10,0.173405528485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1,0.172835189268"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.1,0.172843692344"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.01,0.172855435265"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.001,0.172857056174"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0001,0.172857224346"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1e-05,0.172857241227"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1e-06,0.172857242915"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1e-07,0.172857243084"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1e-08,0.172857243101"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1e-09,0.172857243103"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1e-10,0.172857243103"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1e-11,0.172857243103"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print result_gaps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.97059853  1.43042861  1.76995258 ...,  1.85976093  2.19561739\n",
        "  1.76477948]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}